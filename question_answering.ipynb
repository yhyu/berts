{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from official.nlp import optimization as nlp_opt\n",
    "from official.nlp.bert import tokenization as bert_token\n",
    "\n",
    "from berts.berts import BertEQAModel\n",
    "from berts.utils import get_bert_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_words_seq (InputLayer)    [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_attention_mask (InputLaye [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_segment_mask (InputLayer) [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        [(None, 768), (None, 109482241   input_words_seq[0][0]            \n",
      "                                                                 input_attention_mask[0][0]       \n",
      "                                                                 input_segment_mask[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Equal (TensorFlowOp [(None, None)]       0           input_segment_mask[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 768)    0           keras_layer[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Cast (TensorFlowOpL [(None, None)]       0           tf_op_layer_Equal[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "weighted_layer (WeightedLayer)  (None, None)         768         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul (TensorFlowOpLa [(None, None)]       0           tf_op_layer_Cast[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "weighted_layer_1 (WeightedLayer (None, None)         768         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_1 (TensorFlowOp [(None, None)]       0           tf_op_layer_Cast[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None, None)]       0           weighted_layer[0][0]             \n",
      "                                                                 tf_op_layer_Mul[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_1 (TensorFlow [(None, None)]       0           weighted_layer_1[0][0]           \n",
      "                                                                 tf_op_layer_Mul_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 768)          0           keras_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "ans_start (Activation)          (None, None)         0           tf_op_layer_AddV2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "ans_end (Activation)            (None, None)         0           tf_op_layer_AddV2_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "cls (Dense)                     (None, 1)            769         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 109,484,546\n",
      "Trainable params: 109,484,545\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\"\n",
    "model, bert_layer = BertEQAModel(\n",
    "    bert_url,\n",
    "    return_cls=True\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size: 30522\n"
     ]
    }
   ],
   "source": [
    "# load vocabulary (must be same as pre-trained bert)\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "bert_tokenizer = bert_token.FullTokenizer(vocab_file, to_lower_case)\n",
    "print('vocabulary size:', len(bert_tokenizer.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>qid</th>\n",
       "      <th>answer</th>\n",
       "      <th>ans_start</th>\n",
       "      <th>ans_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>66</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>56be85543aeaaa14008c9065</td>\n",
       "      <td>singing and dancing</td>\n",
       "      <td>54</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>56be85543aeaaa14008c9066</td>\n",
       "      <td>2003</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>56bf6b0f3aeaaa14008c9601</td>\n",
       "      <td>houston , texas</td>\n",
       "      <td>46</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>56bf6b0f3aeaaa14008c9602</td>\n",
       "      <td>late 1990s</td>\n",
       "      <td>68</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cid                       qid               answer  ans_start  ans_end\n",
       "0    1  56be85543aeaaa14008c9063    in the late 1990s         66       69\n",
       "1    1  56be85543aeaaa14008c9065  singing and dancing         54       56\n",
       "2    1  56be85543aeaaa14008c9066                 2003        127      127\n",
       "3    1  56bf6b0f3aeaaa14008c9601      houston , texas         46       48\n",
       "4    1  56bf6b0f3aeaaa14008c9602           late 1990s         68       69"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use preprocessed SQuAD2.0 partial data\n",
    "df_ans = pd.read_csv('data/SQuAD/convert_ans_pos/train_answer_pos.csv', na_filter= False)\n",
    "df_ans = df_ans.drop(columns=['aid'])\n",
    "df_ans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>qid</th>\n",
       "      <th>question</th>\n",
       "      <th>hasAnswer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>when did beyonce start becoming popular ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>56be85543aeaaa14008c9065</td>\n",
       "      <td>what areas did beyonce compete in when she was...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>56be85543aeaaa14008c9066</td>\n",
       "      <td>when did beyonce leave destiny ' s child and b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>56bf6b0f3aeaaa14008c9601</td>\n",
       "      <td>in what city and state did beyonce grow up ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>56bf6b0f3aeaaa14008c9602</td>\n",
       "      <td>in which decade did beyonce become famous ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cid                       qid  \\\n",
       "0    1  56be85543aeaaa14008c9063   \n",
       "1    1  56be85543aeaaa14008c9065   \n",
       "2    1  56be85543aeaaa14008c9066   \n",
       "3    1  56bf6b0f3aeaaa14008c9601   \n",
       "4    1  56bf6b0f3aeaaa14008c9602   \n",
       "\n",
       "                                            question  hasAnswer  \n",
       "0          when did beyonce start becoming popular ?          1  \n",
       "1  what areas did beyonce compete in when she was...          1  \n",
       "2  when did beyonce leave destiny ' s child and b...          1  \n",
       "3       in what city and state did beyonce grow up ?          1  \n",
       "4        in which decade did beyonce become famous ?          1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ques = pd.read_csv('data/SQuAD/preprocess/train_question_tokenized.csv', na_filter= False)\n",
    "df_ques.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>beyonce gi ##selle knowles - carter ( / bi ##ː...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>following the di ##sb ##and ##ment of destiny ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>a self - described \" modern - day feminist \" ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>beyonce gi ##selle knowles was born in houston...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>beyonce attended st . mary ' s elementary scho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cid                                            context\n",
       "0    1  beyonce gi ##selle knowles - carter ( / bi ##ː...\n",
       "1    2  following the di ##sb ##and ##ment of destiny ...\n",
       "2    3  a self - described \" modern - day feminist \" ,...\n",
       "3    4  beyonce gi ##selle knowles was born in houston...\n",
       "4    5  beyonce attended st . mary ' s elementary scho..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_context = pd.read_csv('data/SQuAD/preprocess/train_context_tokenized.csv', na_filter= False)\n",
    "df_context.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>qid</th>\n",
       "      <th>answer</th>\n",
       "      <th>ans_start</th>\n",
       "      <th>ans_end</th>\n",
       "      <th>question</th>\n",
       "      <th>hasAnswer</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>66</td>\n",
       "      <td>69</td>\n",
       "      <td>when did beyonce start becoming popular ?</td>\n",
       "      <td>1</td>\n",
       "      <td>beyonce gi ##selle knowles - carter ( / bi ##ː...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>56be85543aeaaa14008c9065</td>\n",
       "      <td>singing and dancing</td>\n",
       "      <td>54</td>\n",
       "      <td>56</td>\n",
       "      <td>what areas did beyonce compete in when she was...</td>\n",
       "      <td>1</td>\n",
       "      <td>beyonce gi ##selle knowles - carter ( / bi ##ː...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>56be85543aeaaa14008c9066</td>\n",
       "      <td>2003</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>when did beyonce leave destiny ' s child and b...</td>\n",
       "      <td>1</td>\n",
       "      <td>beyonce gi ##selle knowles - carter ( / bi ##ː...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>56bf6b0f3aeaaa14008c9601</td>\n",
       "      <td>houston , texas</td>\n",
       "      <td>46</td>\n",
       "      <td>48</td>\n",
       "      <td>in what city and state did beyonce grow up ?</td>\n",
       "      <td>1</td>\n",
       "      <td>beyonce gi ##selle knowles - carter ( / bi ##ː...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>56bf6b0f3aeaaa14008c9602</td>\n",
       "      <td>late 1990s</td>\n",
       "      <td>68</td>\n",
       "      <td>69</td>\n",
       "      <td>in which decade did beyonce become famous ?</td>\n",
       "      <td>1</td>\n",
       "      <td>beyonce gi ##selle knowles - carter ( / bi ##ː...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cid                       qid               answer  ans_start  ans_end  \\\n",
       "0    1  56be85543aeaaa14008c9063    in the late 1990s         66       69   \n",
       "1    1  56be85543aeaaa14008c9065  singing and dancing         54       56   \n",
       "2    1  56be85543aeaaa14008c9066                 2003        127      127   \n",
       "3    1  56bf6b0f3aeaaa14008c9601      houston , texas         46       48   \n",
       "4    1  56bf6b0f3aeaaa14008c9602           late 1990s         68       69   \n",
       "\n",
       "                                            question  hasAnswer  \\\n",
       "0          when did beyonce start becoming popular ?          1   \n",
       "1  what areas did beyonce compete in when she was...          1   \n",
       "2  when did beyonce leave destiny ' s child and b...          1   \n",
       "3       in what city and state did beyonce grow up ?          1   \n",
       "4        in which decade did beyonce become famous ?          1   \n",
       "\n",
       "                                             context  \n",
       "0  beyonce gi ##selle knowles - carter ( / bi ##ː...  \n",
       "1  beyonce gi ##selle knowles - carter ( / bi ##ː...  \n",
       "2  beyonce gi ##selle knowles - carter ( / bi ##ː...  \n",
       "3  beyonce gi ##selle knowles - carter ( / bi ##ː...  \n",
       "4  beyonce gi ##selle knowles - carter ( / bi ##ː...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join context, question, answer data together\n",
    "df_qa = df_ans.join(df_ques.set_index(['cid', 'qid']), how='inner', on=['cid', 'qid']\n",
    "                   ).join(df_context.set_index('cid'), how='inner', on='cid')\n",
    "df_qa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data size: 130319\n"
     ]
    }
   ],
   "source": [
    "df_qa['question'] = [s.split(\" \") for s in df_qa['question']]\n",
    "df_qa['context'] = [s.split(\" \") for s in df_qa['context']]\n",
    "print('original data size:', len(df_qa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using data size: 124975\n"
     ]
    }
   ],
   "source": [
    "# only use partial data set (context + question < 160), b/c my GPU memory is not big enough for all data\n",
    "df_qa = df_qa[df_qa.apply(lambda x: (len(x['question']) + len(x['context'])) < 300, axis=1)]\n",
    "print('using data size:', len(df_qa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "df_qa = df_qa.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape: (99980, 302) (99980, 302) (99980, 302)\n",
      "training label shape: (99980,) (99980,) (99980,)\n",
      "validation data shape: (24995, 302) (24995, 302) (24995, 302)\n",
      "validation label shape: (24995,) (24995,) (24995,)\n"
     ]
    }
   ],
   "source": [
    "# separate data set into training (80%) and validation (20%) data sets\n",
    "val_size = int(len(df_qa) * 0.2)\n",
    "\n",
    "# prepare bert input data\n",
    "input_words, input_mask, input_seg = get_bert_inputs(bert_tokenizer,\n",
    "                                                     df_qa['question'],\n",
    "                                                     df_qa['context'],\n",
    "                                                     tokenized=True)\n",
    "question_len = [(len(s) + 1) * df_qa['hasAnswer'][i] for i, s in enumerate(df_qa['question'])] # + 1: <SEP>\n",
    "\n",
    "train_input_words, train_input_mask, train_input_seg = input_words[:-val_size], input_mask[:-val_size], input_seg[:-val_size]\n",
    "train_label_cls = tf.constant(df_qa['hasAnswer'][:-val_size])\n",
    "train_label_start = tf.constant(df_qa['ans_start'][:-val_size]) + question_len[:-val_size]\n",
    "train_label_end = tf.constant(df_qa['ans_end'][:-val_size]) + question_len[:-val_size]\n",
    "print('training data shape:', train_input_words.shape, train_input_mask.shape, train_input_seg.shape)\n",
    "print('training label shape:', train_label_cls.shape, train_label_start.shape, train_label_end.shape)\n",
    "\n",
    "valid_input_words, valid_input_mask, valid_input_seg = input_words[-val_size:], input_mask[-val_size:], input_seg[-val_size:]\n",
    "valid_label_cls = tf.constant(df_qa['hasAnswer'][-val_size:])\n",
    "valid_label_start = tf.constant(df_qa['ans_start'][-val_size:]) + question_len[-val_size:]\n",
    "valid_label_end = tf.constant(df_qa['ans_end'][-val_size:]) + question_len[-val_size:]\n",
    "print('validation data shape:', valid_input_words.shape, valid_input_mask.shape, valid_input_seg.shape)\n",
    "print('validation label shape:', valid_label_cls.shape, valid_label_start.shape, valid_label_end.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_loss(y_true, y_pred):\n",
    "    loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=False)\n",
    "    mask = tf.cast(tf.math.logical_not(tf.math.equal(y_true, 0)), loss.dtype) # y_true==0: no answer\n",
    "    # loss.shape: (None,), mask.shape: (None, 1) -> squeeze\n",
    "    loss *= tf.squeeze(mask, axis=1)\n",
    "    return tf.math.reduce_sum(loss)/(tf.math.reduce_sum(mask) + 1e-7)\n",
    "\n",
    "def qa_accuracy(y_true, y_pred):\n",
    "    if y_pred.shape[1] == 1:\n",
    "        return tf.math.reduce_mean(tf.keras.metrics.binary_accuracy(y_true, y_pred))\n",
    "    \n",
    "    acc = tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "    mask = tf.cast(tf.math.logical_not(tf.math.equal(y_true, 0)), acc.dtype) # y_true==0: no answer\n",
    "    acc *= tf.squeeze(mask, axis=1)\n",
    "    return tf.math.reduce_sum(acc)/(tf.math.reduce_sum(mask) + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8 # b/c my GPU memory is not big enough for bigger batch size\n",
    "epochs = 3\n",
    "train_data_size = len(train_label_cls)\n",
    "steps_per_epoch = int(train_data_size / batch_size)\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "warmup_steps = int(epochs * train_data_size * 0.1 / batch_size)\n",
    "\n",
    "# creates an optimizer with learning rate schedule\n",
    "optimizer = nlp_opt.create_optimizer(2e-5, num_train_steps=num_train_steps, num_warmup_steps=warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer,\n",
    "              loss=[qa_loss, qa_loss, 'binary_crossentropy'],\n",
    "              loss_weights=[1.4, 1, 0.6],\n",
    "              metrics=qa_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "12498/12498 [==============================] - 5016s 401ms/step - loss: 4.3357 - ans_start_loss: 1.6748 - ans_end_loss: 1.6486 - cls_loss: 0.5705 - ans_start_qa_accuracy: 0.5482 - ans_end_qa_accuracy: 0.5722 - cls_qa_accuracy: 0.7067 - val_loss: 2.8426 - val_ans_start_loss: 1.0840 - val_ans_end_loss: 1.0536 - val_cls_loss: 0.4525 - val_ans_start_qa_accuracy: 0.6792 - val_ans_end_qa_accuracy: 0.6953 - val_cls_qa_accuracy: 0.7864\n",
      "Epoch 2/3\n",
      "12498/12498 [==============================] - 5028s 402ms/step - loss: 2.3458 - ans_start_loss: 0.8803 - ans_end_loss: 0.8535 - cls_loss: 0.4331 - ans_start_qa_accuracy: 0.7254 - ans_end_qa_accuracy: 0.7469 - cls_qa_accuracy: 0.7984 - val_loss: 2.6552 - val_ans_start_loss: 1.0303 - val_ans_end_loss: 0.9826 - val_cls_loss: 0.3835 - val_ans_start_qa_accuracy: 0.6992 - val_ans_end_qa_accuracy: 0.7138 - val_cls_qa_accuracy: 0.8235\n",
      "Epoch 3/3\n",
      "12498/12498 [==============================] - 5036s 403ms/step - loss: 1.5655 - ans_start_loss: 0.5618 - ans_end_loss: 0.5649 - cls_loss: 0.3568 - ans_start_qa_accuracy: 0.8111 - ans_end_qa_accuracy: 0.8218 - cls_qa_accuracy: 0.8406 - val_loss: 2.8180 - val_ans_start_loss: 1.1044 - val_ans_end_loss: 1.0462 - val_cls_loss: 0.3761 - val_ans_start_qa_accuracy: 0.7002 - val_ans_end_qa_accuracy: 0.7183 - val_cls_qa_accuracy: 0.8336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c5a20d7708>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([train_input_words, train_input_mask, train_input_seg],\n",
    "          [train_label_start, train_label_end, train_label_cls],\n",
    "          validation_data=([valid_input_words, valid_input_mask, valid_input_seg],\n",
    "                           [valid_label_start, valid_label_end, valid_label_cls]),\n",
    "          batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tokens_to_sentence(tokens):\n",
    "    sentence = ''\n",
    "    for i, tok in enumerate(tokens):\n",
    "        if i == 0 or tok.startswith('##'):\n",
    "            sentence += tok.lstrip('#')\n",
    "        else:\n",
    "            sentence += (' ' + tok)\n",
    "    return sentence\n",
    "\n",
    "def get_validation_prediction(model, tokenizer, idx):\n",
    "    ds, de, cls = model.predict([valid_input_words[idx:idx+1], valid_input_mask[idx:idx+1], valid_input_seg[idx:idx+1]])\n",
    "    ds, de, cls = tf.math.argmax(ds[0]).numpy(), tf.math.argmax(de[0]).numpy(), cls[0][0]\n",
    "    answer = ''\n",
    "    if cls > 0.5:\n",
    "        answer = convert_tokens_to_sentence(tokenizer.convert_ids_to_tokens(valid_input_words[idx][ds:de+1].numpy()))\n",
    "    \n",
    "    return cls, ds, de, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_cls(cls):\n",
    "    if cls > 0.5:\n",
    "        return 'has answer'\n",
    "    return 'no answer'\n",
    "\n",
    "def output_result(model, tokenizer, idx):\n",
    "    cls, ds, de, answer = get_validation_prediction(model, tokenizer, idx)\n",
    "    print(\"context:\")\n",
    "    print(convert_tokens_to_sentence(df_qa['context'][len(df_qa) - val_size + idx]))\n",
    "    print(\"question:\")\n",
    "    print(convert_tokens_to_sentence(df_qa['question'][len(df_qa) - val_size + idx]))\n",
    "    print(\"validation data index '%d' prediction:\" % (idx))\n",
    "    print(\"\\tcls(%f): %s, ds(%d), de(%d), answer: %s\" % (cls, output_cls(cls), ds, de, answer))\n",
    "\n",
    "    print(\"ground true data index '%d':\" % (idx))\n",
    "    print(\"\\tcls(%d): %s, ds(%d), de(%d), answer: %s\" %\n",
    "          (valid_label_cls[idx].numpy(), output_cls(valid_label_cls[idx].numpy()),\n",
    "           valid_label_start[idx].numpy(),\n",
    "           valid_label_end[idx].numpy(),\n",
    "           convert_tokens_to_sentence(df_qa['answer'][len(df_qa) - val_size + idx].split(\" \"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context:\n",
      "synthetic crude oil , also known as syncrude , is the output from a bitumen upgrader facility used in connection with oil sand production in canada . bituminous sands are mined using enormous ( 100 ton capacity ) power shovels and loaded into even larger ( 400 ton capacity ) dump trucks for movement to an upgrading facility . the process used to extract the bitumen from the sand is a hot water process originally developed by dr . karl clark of the university of alberta during the 1920s . after extraction from the sand , the bitumen is fed into a bitumen upgrader which converts it into a light crude oil equivalent . this synthetic substance is fluid enough to be transferred through conventional oil pipelines and can be fed into conventional oil refineries without any further treatment . by 2015 canadian bitumen upgraders were producing over 1 million barrels ( 160×10 ^ 3 m3 ) per day of synthetic crude oil , of which 75 % was exported to oil refineries in the united states . [SEP]\n",
      "question:\n",
      "what is also known as synclark oil ? [SEP]\n",
      "validation data index '1000' prediction:\n",
      "\tcls(0.234120): no answer, ds(13), de(15), answer: \n",
      "ground true data index '1000':\n",
      "\tcls(0): no answer, ds(0), de(0), answer: \n"
     ]
    }
   ],
   "source": [
    "output_result(model, bert_tokenizer, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context:\n",
      "in january 1989 , madonna signed an endorsement deal with soft - drink manufacturer , pepsi . in one of her pepsi commercials , she debuted her song \" like a prayer \" . the corresponding music video featured many catholic symbols such as stigmata and cross burning , and a dream of making love to a saint , leading the vatican to condemn the video . religious groups sought to ban the commercial and boycott pepsi products . pepsi revoked the commercial and canceled her sponsorship contract . the song was included on madonna ' s fourth studio album , like a prayer , which was co - written and co - produced by patrick leonard and stephen bray . madonna received positive feedback for the album , with rolling stone writing that it was \" as close to art as pop music gets \" . like a prayer peaked at number one on the billboard 200 and sold 15 million copies worldwide , with 4 million copies sold in the u . s . alone . six singles were released from the album , including \" like a prayer \" , which reached number one , and \" express yourself \" and \" cherish \" , both peaking at number two . by the end of the 1980s , madonna was named as the \" artist of the decade \" by mtv , billboard and musician magazine . [SEP]\n",
      "question:\n",
      "when did madonna sign an endorsement deal with pepsi ? [SEP]\n",
      "validation data index '1100' prediction:\n",
      "\tcls(0.999832): has answer, ds(13), de(14), answer: january 1989\n",
      "ground true data index '1100':\n",
      "\tcls(1): has answer, ds(13), de(14), answer: january 1989\n"
     ]
    }
   ],
   "source": [
    "output_result(model, bert_tokenizer, 1100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context:\n",
      "despite being eliminated earlier in the season , chris daughtry ( as lead of the band daughtry ) became the most successful recording artist from this season . other contestants , such as hicks , mcphee , bucky covington , mandisa , kellie pickler , and elliott yamin have had varying levels of success . [SEP]\n",
      "question:\n",
      "what is the name if the band that has chris daughtry as its lead singer ? [SEP]\n",
      "validation data index '1110' prediction:\n",
      "\tcls(0.985497): has answer, ds(37), de(40), answer: band daughtry\n",
      "ground true data index '1110':\n",
      "\tcls(1): has answer, ds(29), de(31), answer: daughtry\n"
     ]
    }
   ],
   "source": [
    "output_result(model, bert_tokenizer, 1110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
